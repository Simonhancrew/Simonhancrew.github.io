---
layout: post
title: "Milestone R-CNN"
date: 2021-10-11
---

目标检测，深度学习方向的开山之作。mAP在VOC2012上比之前的SOTA提升了30%，达到了53.3%。

文章开篇的abs提及本文的主要贡献就是两点告诉我们两件事，

1. 一个很深的神经网络可以用于自底向上的区域选择，方便定位和分割（好像是废话）
2. 微调迁移是有用的

### how it works

不同于之前的滑窗，本文只在可能出现目标的区域采用CNN做定位，然后判断具体的物体类别

预选区域用的Selective Search，之后CNN将特征提取出来，送入一个SVM分类器。

### 详细的设计

详细的三大块设计和之前一样，就是

`1`可能区域的提出，`2`然后CNN出特征，`3`之后送入分类器，`4`Bbox reg预测每个已识别区域的边框

输入一张图片，搜索出所有的可能是物体的区域（selective search），选出2k多个候选框，大体的思路就是

1. 使用一种过分割手段，将图像分割成小区域 (1k~2k 个)
2. 查看现有小区域，按照合并规则合并可能性最高的相邻两个区域。重复直到整张图像合并成一个区域位置
3. 输出所有曾经存在过的区域，所谓候选区域

之后将这个区域resize成227 * 227的矩形图送进CNN，paper里验证了两种缩放的方法

1. 各向异性缩放
2. 各向同性缩放

经过文章的多次实验之后，采用各向异性缩放、padding=16的精度最高。

然后就是CNN对目标特征做一个提取了，网络框架可以选择的是VGG16和Alexnet，VGG16的精度要高一点。

最后送出的是一个4096维度的特征向量。然后对于每一个类别，使用为这一类训练的SVM分类器对提取的特征向量进行打分，得到测试图片中对于所有region proposals的对于这一类的分数，再使用贪心的非极大值抑制（NMS）去除相交的多余的框。再对这些框进行canny边缘检测，就可以得到bounding-box(then B-BoxRegression)

然后关于CNN提取特征之后过SVM的骚操作，因为CNN做训练的时候要求比较低，一个box如果包含了物体的一部分也算作正例样本，之后SVM做训练的时候就比较严格了，必须把整个物体包括进去才是ok的。

具体的实现还是要扣代码配合论文食用

然后想了一下R-CNN比较慢的原因

1. 选择性搜索算法慢比较能理解
2. CNN提取特征也挺慢的
3. SVM
4. 最后还有一个回归模型收紧边框界也挺离谱