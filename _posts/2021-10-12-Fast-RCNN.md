---
title: fast-RCNN
date: 2021-10-12 14:10:00 +0800
categories: [Blogging]
tags: [writing]
---

abs里面直接稳准狠的告诉你，文章用了一些创新的技术，让训练和测试都更快了，而且也更准了。

本文的主要贡献就是提出了一种优化RCNN的思路，不用对ss找到的2000多个区域进行CNN，而是进行一次CNN，之后通过一个ROI池化层将所有的感兴趣区域修正到合适的size，然后输入到FC中。

### how it works

简单的说其实就是之前RCNN的优化，主要就是4步：

1. input image to CNN
2. 通过一个ROI池化层
3. 网络的顶层做softmax分类输出，
4. 一个线性回归层，输出相应的bbox

缺点还是比较明显，ss还是存在的一个瓶颈，速度依然不理想。

### 详细的设计

图片输入，CNN提取特征，之后假设SS已经生成了N个候选区域，这些RoI的大小各异，因此需要额外操作提取相同尺寸的特征，以便于连结后输出。

RoI池化层就是将CNN的输出和SS的输出作为输入，输出连结后的各个区域抽取的特征

最后的预测，通过全连接层将输出形状变换为 n×d ，其中超参数 d 取决于模型设计。

+ 预测类别时，将全连接层的输出的形状再变换到 n×q 并使用softmax回归（q 为类别个数）
+ 预测边界框时，将全连接层的输出的形状变换为 n×4。（为每个提议区域预测类别和边界框）

而得益于RoI Pooling，前向时为了得到特定的RoI，需要处理更大范围的图片，这变相提高了输入的感受野。

因此，可以认为Fast R-CNN好就好在特征提取与Roipooling部分共享特征与参数了。

而刚刚提到的好处建立在一个基础上：即**每次训练的RoI都是来自同一张图片**，因此Fast R-CNN训练时的训练样本需要特定的采样策略。

假设SGD的minibatch有R个输入，涉及N张完整图片，那一个batch里每个图就有R/N个RoI。

N小了，那一个batch就有更多图可以前反向时共享特征，提高处理效率。

最后还要关注一下这个损失函数，贼拉长的多任务损失函数，主要由两部分组成：

1. 分类的负对数损失
2. 定位损失

里面还有些SVD加速的内容，全连接层速度能加速不少，目前好像不常用了

